{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Modules\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "qin_est = pd.read_csv(\"~/Metagenomics/qin.2014.csv\")\n",
    "qin_est = pd.DataFrame(qin_est)\n",
    "qin_est.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predictors and response variable\n",
    "x_qin = qin_est[qin_est.columns[:-1]]\n",
    "y_qin = qin_est['study_condition']\n",
    "x_qin.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {\"C\": 2 ** np.arange(-5, 15, 2, dtype = float),\n",
    "          \"gamma\": 2 ** np.arange(-15, 3, 2, dtype = float)}\n",
    "\n",
    "# We will use a Support Vector Classifier with \"rbf\" kernel\n",
    "svm = SVC(kernel=\"rbf\")\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 20\n",
    "\n",
    "# Arrays to store scores\n",
    "non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "nested_scores = np.zeros(NUM_TRIALS)\n",
    "\n",
    "    \n",
    "for i in range(NUM_TRIALS):\n",
    "    \n",
    "    inner_cv = KFold(n_splits=5, shuffle=True, random_state=i)\n",
    "    outer_cv = KFold(n_splits=10, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=inner_cv, scoring='roc_auc')\n",
    "    clf.fit(x_qin, y_qin)\n",
    "    non_nested_scores = clf.best_score_\n",
    "    \n",
    "    nested_score = cross_val_score(clf, X=x_qin, y=y_qin, cv=outer_cv ,scoring='roc_auc')\n",
    "    nested_scores[i] = nested_score.mean()\n",
    "\n",
    "avg_score = nested_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scores on each trial for nested CV\n",
    "# https://matplotlib.org/tutorials/intermediate/legend_guide.html\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "nested_line, = plt.plot(nested_scores, color='b')\n",
    "plt.ylabel(\"score\", fontsize=\"14\")\n",
    "# Place a legend to the right of the subplot\n",
    "plt.legend([nested_line], [\"Nested CV\"], bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.title(\"Nested Cross Validation of SVM after 20 Independent Runs on Cirrhosis Dataset\", x=.5, y=1.1, fontsize=\"15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = math.floor(math.sqrt(len(x_qin.columns)))\n",
    "print(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "p_grid_rf = { # 1st param grid, corresponding to RandomForestRegressor\n",
    "                            'n_estimators': [500],\n",
    "                            'max_features': [math.floor(math.sqrt(len(x_qin.columns)))],\n",
    "                            'citerion': ['gini']}\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 20\n",
    "\n",
    "# Arrays to store scores\n",
    "rf_scores = np.zeros(NUM_TRIALS)\n",
    "\n",
    "for i in range(NUM_TRIALS):\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=500, criterion='gini', max_features=feat)\n",
    "    scores = cross_val_score(clf, x_qin, y_qin, cv=10, scoring='roc_auc')\n",
    "    rf_scores[i] = scores.mean()\n",
    "\n",
    "print(\"AUC: %0.2f\" % (scores.mean()))\n",
    "print(\"Average AUC: %0.2f\" % (rf_scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split for the hyperparameter tuning\n",
    "X_train, x_test, Y_train, y_test = train_test_split(x_qin, y_qin,\n",
    "                                                    test_size = 0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance RF\n",
    "rf = RandomForestClassifier(n_estimators=500, criterion='gini', max_features=feat)\n",
    "rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical feature importances\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 125, 150, 175, 200]\n",
    "auc_scores = np.zeros(len(k))\n",
    "for i in range(len(k)):\n",
    "    X_feat_train = X_train.iloc[:, rf.feature_importances_.argsort()[-k[i]:]]\n",
    "\n",
    "    rf_feat = RandomForestClassifier(n_estimators=500, criterion='gini', max_features=math.floor(math.sqrt(k[i])))\n",
    "    scores = cross_val_score(rf_feat, X_feat_train, Y_train, cv=5, scoring='roc_auc')\n",
    "    auc_scores[i] = scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the number of features that gives that best auc\n",
    "print(auc_scores)\n",
    "auc_scores.argsort()[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feat = int(auc_scores.argsort()[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest after feature importance\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 20\n",
    "\n",
    "# Arrays to store scores\n",
    "rf_feat_scores = np.zeros(NUM_TRIALS)\n",
    "\n",
    "# Subset the original features dataset to include only the features selected in previous step\n",
    "x_qin_feat = x_qin.iloc[:, rf.feature_importances_.argsort()[-k[best_feat]:]]\n",
    "\n",
    "for i in range(NUM_TRIALS):\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=500, criterion='gini', \n",
    "                                 max_features=math.floor(math.sqrt(len(x_qin_feat.columns))))\n",
    "    scores = cross_val_score(clf, x_qin_feat, y_qin, cv=10, scoring='roc_auc')\n",
    "    rf_feat_scores[i] = scores.mean()\n",
    "    \n",
    "print(\"AUC: %0.2f\" % (scores.mean()))\n",
    "print(\"Average AUC: %0.2f\" % (rf_feat_scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores.mean().round(5))\n",
    "print(rf_feat_scores.mean().round(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso, can skip\n",
    "\n",
    "# Set up possible values of parameters to optimize over\n",
    "alpha = 10 ** np.arange(-4, -0.5, 0.5, dtype = float)\n",
    "\n",
    "lasso = LassoCV(cv=5, random_state=0, alphas=alpha, tol=0.08)\n",
    "le = preprocessing.LabelEncoder()\n",
    "Y_train = le.fit_transform(Y_train)\n",
    "lasso.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso\n",
    "alpha = 10 ** np.arange(-4, -0.5, 0.5, dtype = float)\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 20\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_qin = le.fit_transform(y_qin)\n",
    "\n",
    "# Arrays to store scores\n",
    "non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "nested_scores = np.zeros(NUM_TRIALS)\n",
    "\n",
    "for i in range(NUM_TRIALS):\n",
    "    inner_cv = KFold(n_splits=5, shuffle=True, random_state=i)\n",
    "    outer_cv = KFold(n_splits=10, shuffle=True, random_state=i)\n",
    "\n",
    "    lasso = LassoCV(cv=inner_cv, random_state=i, alphas=alpha, tol=0.08).fit(x_qin, y_qin)\n",
    "    non_nested_scores = lasso.alpha_\n",
    "\n",
    "    nested_score = cross_val_score(lasso, X=x_qin, y=y_qin, cv=outer_cv, scoring='roc_auc')\n",
    "    nested_scores[i] = nested_score.mean()\n",
    "\n",
    "print(\"AUC: %0.2f\" % (nested_score.mean()))\n",
    "print(\"Average AUC: %0.2f\" % (nested_scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up possible values of parameters to optimize over\n",
    "alpha = 10 ** np.arange(-4, -0.5, 0.5, dtype = float)\n",
    "\n",
    "lasso = LassoCV(cv=5, random_state=0, alphas=alpha, tol=0.08)\n",
    "le = preprocessing.LabelEncoder()\n",
    "Y_train = le.fit_transform(Y_train)\n",
    "sel_ = SelectFromModel(lasso)\n",
    "sel_.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sel_.get_support()))\n",
    "print(len(x_qin.columns))\n",
    "sel_.transform(X_train).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_selected_feat = x_qin.iloc[:, sel_.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest after feature importance by Lasso\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 20\n",
    "\n",
    "# Arrays to store scores\n",
    "rf_feat_scores = np.zeros(NUM_TRIALS)\n",
    "\n",
    "for i in range(NUM_TRIALS):\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=500, criterion='gini', \n",
    "                                 max_features=math.floor(math.sqrt(len(x_selected_feat.columns))))\n",
    "    scores = cross_val_score(clf, x_selected_feat, y_qin, cv=10, scoring='roc_auc')\n",
    "    rf_feat_scores[i] = scores.mean()\n",
    "    \n",
    "print(\"AUC: %0.2f\" % (scores.mean()))\n",
    "print(\"Average AUC: %0.2f\" % (rf_feat_scores.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_feat_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENet\n",
    "alpha = 10 ** np.arange(-4, -0.5, 0.5, dtype = float)\n",
    "l1_ratio = np.array([0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1.0])\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 20\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_qin = le.fit_transform(y_qin)\n",
    "\n",
    "# Arrays to store scores\n",
    "non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "nested_scores = np.zeros(NUM_TRIALS)\n",
    "\n",
    "for i in range(NUM_TRIALS):\n",
    "    inner_cv = KFold(n_splits=5, shuffle=True, random_state=i)\n",
    "    outer_cv = KFold(n_splits=10, shuffle=True, random_state=i)\n",
    "\n",
    "    enet = ElasticNetCV(cv=inner_cv, random_state=i, tol=0.08,\n",
    "                                l1_ratio=l1_ratio, alphas=alpha).fit(x_qin, y_qin)\n",
    "\n",
    "    nested_score = cross_val_score(lasso, X=x_qin, y=y_qin, cv=outer_cv, scoring='roc_auc')\n",
    "    nested_scores[i] = nested_score.mean()\n",
    "\n",
    "print(\"AUC: %0.2f\" % (nested_score.mean()))\n",
    "print(\"Average AUC: %0.2f\" % (nested_scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElasticNetCV(cv=inner_cv, random_state=0, tol=0.08,\n",
    "                                l1_ratio=l1_ratio, alphas=alpha).fit(x_qin, y_qin).score(x_qin, y_qin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up possible values of parameters to optimize over\n",
    "alpha = 10 ** np.arange(-4, -0.5, 0.5, dtype = float)\n",
    "l1_ratio = np.array([0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1.0])\n",
    "\n",
    "enet = ElasticNetCV(cv=inner_cv, random_state=i, tol=0.08,\n",
    "                                l1_ratio=l1_ratio, alphas=alpha)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "Y_train = le.fit_transform(Y_train)\n",
    "sel_ = SelectFromModel(lasso)\n",
    "sel_.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sel_.get_support()))\n",
    "print(len(x_qin.columns))\n",
    "sel_.transform(X_train).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_selected_feat = x_qin.iloc[:, sel_.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest after feature importance by ENet\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 20\n",
    "\n",
    "# Arrays to store scores\n",
    "rf_feat_scores = np.zeros(NUM_TRIALS)\n",
    "\n",
    "for i in range(NUM_TRIALS):\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=500, criterion='gini', \n",
    "                                 max_features=math.floor(math.sqrt(len(x_selected_feat.columns))))\n",
    "    scores = cross_val_score(clf, x_selected_feat, y_qin, cv=10, scoring='roc_auc')\n",
    "    rf_feat_scores[i] = scores.mean()\n",
    "    \n",
    "print(\"AUC: %0.2f\" % (scores.mean()))\n",
    "print(\"Average AUC: %0.2f\" % (rf_feat_scores.mean()))\n",
    "\n",
    "rf_feat_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
